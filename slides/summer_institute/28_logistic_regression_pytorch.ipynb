{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiVM4lOtpJVt",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Logistic regression in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "6nKZWgTDvTTK",
    "outputId": "264fb349-cfa2-42cd-ddb4-1efc49f2d883",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLAIR</th>\n",
       "      <th>PD</th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>FLAIR_10</th>\n",
       "      <th>PD_10</th>\n",
       "      <th>T1_10</th>\n",
       "      <th>T2_10</th>\n",
       "      <th>FLAIR_20</th>\n",
       "      <th>PD_20</th>\n",
       "      <th>T1_20</th>\n",
       "      <th>T2_20</th>\n",
       "      <th>GOLD_Lesions</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.143692</td>\n",
       "      <td>1.586219</td>\n",
       "      <td>-0.799859</td>\n",
       "      <td>1.634467</td>\n",
       "      <td>0.437568</td>\n",
       "      <td>0.823800</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>0.573663</td>\n",
       "      <td>0.279832</td>\n",
       "      <td>0.548341</td>\n",
       "      <td>0.219136</td>\n",
       "      <td>0.298662</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.181648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.652552</td>\n",
       "      <td>1.766672</td>\n",
       "      <td>-1.250992</td>\n",
       "      <td>0.921230</td>\n",
       "      <td>0.663037</td>\n",
       "      <td>0.880250</td>\n",
       "      <td>-0.422060</td>\n",
       "      <td>0.542597</td>\n",
       "      <td>0.422182</td>\n",
       "      <td>0.549711</td>\n",
       "      <td>0.061573</td>\n",
       "      <td>0.280972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.426453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.036099</td>\n",
       "      <td>0.262042</td>\n",
       "      <td>-0.858565</td>\n",
       "      <td>-0.058211</td>\n",
       "      <td>-0.044280</td>\n",
       "      <td>-0.308569</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>-0.256075</td>\n",
       "      <td>-0.136532</td>\n",
       "      <td>-0.350905</td>\n",
       "      <td>0.020673</td>\n",
       "      <td>-0.259914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.614749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.037692</td>\n",
       "      <td>0.011104</td>\n",
       "      <td>-1.228796</td>\n",
       "      <td>-0.470222</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>-0.000498</td>\n",
       "      <td>-0.395575</td>\n",
       "      <td>-0.221900</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>-0.003085</td>\n",
       "      <td>-0.193249</td>\n",
       "      <td>-0.139284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.955175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.580589</td>\n",
       "      <td>1.730152</td>\n",
       "      <td>-0.860949</td>\n",
       "      <td>1.245609</td>\n",
       "      <td>0.617957</td>\n",
       "      <td>0.866352</td>\n",
       "      <td>-0.099919</td>\n",
       "      <td>0.384261</td>\n",
       "      <td>0.391133</td>\n",
       "      <td>0.608826</td>\n",
       "      <td>0.071648</td>\n",
       "      <td>0.340601</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.376909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FLAIR        PD        T1        T2  FLAIR_10     PD_10     T1_10  \\\n",
       "0  1.143692  1.586219 -0.799859  1.634467  0.437568  0.823800 -0.002059   \n",
       "1  1.652552  1.766672 -1.250992  0.921230  0.663037  0.880250 -0.422060   \n",
       "2  1.036099  0.262042 -0.858565 -0.058211 -0.044280 -0.308569  0.014766   \n",
       "3  1.037692  0.011104 -1.228796 -0.470222 -0.013971 -0.000498 -0.395575   \n",
       "4  1.580589  1.730152 -0.860949  1.245609  0.617957  0.866352 -0.099919   \n",
       "\n",
       "      T2_10  FLAIR_20     PD_20     T1_20     T2_20  GOLD_Lesions  y         x  \n",
       "0  0.573663  0.279832  0.548341  0.219136  0.298662             0  1  1.181648  \n",
       "1  0.542597  0.422182  0.549711  0.061573  0.280972             0  1  1.426453  \n",
       "2 -0.256075 -0.136532 -0.350905  0.020673 -0.259914             0  0 -0.614749  \n",
       "3 -0.221900  0.000807 -0.003085 -0.193249 -0.139284             0  0 -0.955175  \n",
       "4  0.384261  0.391133  0.608826  0.071648  0.340601             0  1  1.376909  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## Read in the data and display a few rows\n",
    "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")\n",
    "dat.head(4)\n",
    "\n",
    "## Create a binary outcome variable (people will use gold lesions in HW)\n",
    "m = np.median(dat.T2)\n",
    "dat = dat.assign(y = (dat.T2 > m) * 1 )\n",
    "## Create a normalized regression variable\n",
    "dat = dat.assign(x = (dat.PD - np.mean(dat.PD)) / np.std(dat.PD))\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We now perform logistic regression using PyTorch. We'll start by preparing our dataset.We read the dataset from a CSV file and display the first few rows to inspect the data structure. We create a binary outcome variable y, indicating whether the T2 value is above the median.\n",
    "We normalize the PD variable and assign it to a new column x.\n",
    "This preprocessing is essential for setting up our logistic regression model, ensuring the variables are in the correct format and scale for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "ehiVfmYHJ4EL",
    "outputId": "eb701a2c-88e2-46ee-b2cf-3d5b6cc8eaa8",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.427855\n",
      "         Iterations 7\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0367      0.269      0.136      0.892      -0.491       0.565\n",
      "x              2.2226      0.436      5.095      0.000       1.368       3.078\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "fit = smf.logit('y ~ x', data = dat).fit()\n",
    "print(fit.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To perform logistic regression, we'll use the statsmodels library to fit the model. We'll use the preprocessed dataset with our binary outcome variable y and normalized predictor variable x. We specify our logistic regression model.\n",
    "We fit the model to the data.\n",
    "Then print the second summary table, which contains the coefficients of the logistic regression model.\n",
    "The summary provides important details such as the coefficients, standard errors, z-values, and p-values for the predictors. This information helps us understand the relationship between x (normalized PD) and y (binary outcome), and assess the significance of the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "F6gUNlf6LbJc",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The in sample predictions\n",
    "yhat = 1 / (1 + np.exp(-fit.fittedvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Next, weâ€™ll generate in-sample predictions from our logistic regression model using the fitted values. This step transforms the linear predictions from the model into probabilities that lie between 0 and 1, which is appropriate for our binary outcome variable. These predicted probabilities help us understand the likelihood of the outcome being 1 (e.g., having a higher T2 value) given the predictor variable x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9LZ4MgGEPxEN",
    "outputId": "6fe594a1-85f9-4644-f41c-6991e120e91c",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([100, 1]), torch.Size([100, 1]), [100, 1]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = dat.shape[0]\n",
    "\n",
    "## Get the y and x from \n",
    "xtraining = torch.from_numpy(dat['x'].values)\n",
    "ytraining = torch.from_numpy(dat['y'].values)\n",
    "\n",
    "## PT wants floats\n",
    "xtraining = xtraining.float()\n",
    "ytraining = ytraining.float()\n",
    "\n",
    "## Dimension is 1xn not nx1\n",
    "## squeeze the second dimension\n",
    "xtraining = xtraining.unsqueeze(1)\n",
    "ytraining = ytraining.unsqueeze(1)\n",
    "\n",
    "## Show that everything is the right size\n",
    "[xtraining.shape, ytraining.shape, [n, 1] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To prepare our data for logistic regression using PyTorch we need to convert it into PyTorch tensors. We convert our predictors (x) and outcomes (y) from NumPy arrays to PyTorch tensors. We ensure data type compatibility by converting to float and adjust dimensions using unsqueeze to make sure the tensors are of shape (1xn), suitable for PyTorch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OZKrXwTjPdrB",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Doing it more now the pytorch docs recommend; Example taken from \n",
    "## https://medium.com/biaslyai/pytorch-linear-and-logistic-regression-models-5c5f0da2cb9\n",
    "\n",
    "class LogisticRegression(torch.nn.Module): ## A class that defines the model\n",
    "     def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1, bias = True)\n",
    "     def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "model = LogisticRegression() ## Then the model is simply  \n",
    "loss_fn = torch.nn.BCELoss()  ## MSE is the loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) ## Set the optimizer\n",
    "for t in range(100000):  ## Loop over iterations\n",
    "  y_pred = model(xtraining)  ## Forward propagation\n",
    "  loss = loss_fn(y_pred, ytraining)  ## the loss for this interation \n",
    "  optimizer.zero_grad()  ## Zero out the gradients before adding them up\n",
    "  loss.backward()  ## Backprop\n",
    "  optimizer.step()  ## Optimization step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To implement logistic regression using PyTorch, we define a model class LogisticRegression that inherits from torch.nn.Module. This allows us to encapsulate our model and its operations neatly. We define a LogisticRegression class where self.linear is a linear layer followed by a sigmoid activation function (torch.sigmoid) in the forward method. We use Binary Cross Entropy Loss as our loss function, suitable for binary classification tasks.\n",
    "Stochastic Gradient Descent is chosen as the optimizer with specified learning rate \n",
    "During each iteration we perform forward propagation, compute the loss, backpropagate the gradients, and optimize the model parameters.\n",
    "This structured approach in PyTorch allows us to efficiently train and optimize our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fd1wjXgukgqs",
    "outputId": "91f22597-1686-4b25-ee01-67dcba4753ca",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f080edc2230>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoVUlEQVR4nO3deXhV1b3/8ff3ZGCeZJIpTCIq4EAi4MigKOBAq7Va+mt7vfWqt+LUWseCilrnWatFr7W9leotWkEFUakKDkEIDgyKYjQhgiIhzENyzlm/P1aChwzkAGfIOfm8nidPWTn77L32g3663Hut7zLnHCIikvoCye6AiIjEhgJdRCRNKNBFRNKEAl1EJE0o0EVE0kRmsi7coUMH16tXr2RdXkQkJRUUFKxzznWs7bOkBXqvXr1YtGhRsi4vIpKSzKyors/0yEVEJE0o0EVE0oQCXUQkTSjQRUTShAJdRCRN1BvoZvaUma01s6V1fG5m9pCZrTSzT8xscOy7KSIi9YlmhP40MGYPn48F+lX+XAg8tv/dEhFJU+EwhIJxOXW9ge6cmwes38Mh44G/OS8faGtmXWLVQRGRtLHuC7Y8PpoF/3sDBUVlMT99LJ6hdwNWRbRLKn9Xg5ldaGaLzGzR999/H4NLi4ikgFAFzL+X8GPH0nLtIrp/NZ3zn5wX81CPRaBbLb+rddcM59xU51yecy6vY8daV66KiKSXNR/DE6Ng7hQCoXL+GRrO2J1/ZGswk/zC0pheKhZL/0uAHhHt7sDqGJxXRCR1VeyAt++Edx8EF4K2OXw+5FYmzc6mwsJkZQYY1qd9TC8Zi0CfCUw0s2eBocBG59yaGJxXRCQ1Fb0PMydC6UrAYOjFMGoSBzdpyTPdysgvLGVYn/bk9mwX08vWG+hm9g9gBNDBzEqAG4EsAOfc48AsYBywEtgGnB/THoqIpIqdm+GNm2HhE77d4WA48xHIGbrrkNye7WIe5FXqDXTn3M/q+dwBl8SsRyIiqWjlG/DSFbBxFQQy4bgr4MTfQ1ZTCoriNyqPlLTyuSIiaWHbephzPXz8D9/ucoQflXc5HICCojJ+/mQ+5cEw2ZkBnrlgWPJG6CIiUodlL8Ksq2Dr95DRBEZeB8dcChk/RGt+YSnlwTBhBxXBMPmFpQp0EZEGY/O38Mrv4LOXfTvnWDjzYehw0G6HFRSV8c2G7WRmBAiF4jOzJZICXUQkWs7BR8/4Ryw7NkJ2Sxh9M+T+JwR2X9YT+aglM2CcNySHswZ31zN0EZGkK/saXrocCt/y7YNGw+n3Q9setR7+/OISdlaEcUAo7OjatllcwxwU6CIiexYOwQdPwNyboWIbNGsHY+6Ew38KVttCeT86n15QsmvJfEbA4vqopYoCXUSkLt+vgBkToeQD3x7wYxh7N7Tcc+mS/MJSgqEw4GujnJPXI+6jc1Cgi4jUFKqAdx+At++CUDm0PBBOuxcOPT2qrw/r057szAAVQf8i9KzB3ePb30oKdBGRSKs/9KPy7yr39Bn8Sxh9CzRrG/Upcnu245kLhiVkMVEkBbqICEDFdnjrdnjvYXBhaNsTznwI+oyI6uvVV4PGc4l/XRToIiJfvwszL4X1XwIGwy6BUTdAdouovp7I1aB7okAXkcZrxyZ44yZY9D++3fEQv2y/x9FRn6KgqIwH3vg8YatB90SBLiKN0+evwctXwqYSX0zrhN/5n8wmUZ9i2oJiJr24hFDl/MSAEffVoHuiQBeRxmVrKcy5Dj55zre7HuVH5QcO3KvTTFtQzA3/WrLb9myDurVh8hkDkjI6BwW6iDQWzsGyF2DW1bBtHWQ2hZE3wLDf7FZMKxoFRWVMnrG0xl6bA7u1SVqYgwJdRBqDTWvgld/Cilm+3fN4P4Olfd99Ot0Li0sIhneP86wMS9h887oo0EUkfTkHi/8Gr02CnRshuxWccgsM/lWNYlrRKigq45+LVu1qBwxOPrQzFw3vm9TROSjQRSRdrf8KXroMvprn2/1O9cW02nTbr9PmF5buGp0bcN6QHP7440H72dnYUKCLSHoJh2DB4zD3Fghuh+btYexdMPDsOotp1Sdy0VD1Zf1nJ/kxSyQFuoikj++W+wVC3yzy7YE/gbF3QosO+3zKaQuKmTxjKWHndi0aSsay/mgo0EUk9QXL4Z37YN49EK6AVl3h9Pug/9j9Ou20BcX84cUlVL3/LK9cNHTJyIMaVJBXUaCLSGr7psAX01q73Ldzz/e7CDVts1+nrR7mAAFLTF3zfaVAF5HUVL4N3rwN8v/ki2m16+2nIvY+cb9PXTXPfPcwhynjBzbIkXkVBbqIpJ6v5vtn5WVfgQXg2EthxPWQ3Twmp88vLCXsfkjzgMGtPxrEhKE5MTl/vCjQRSR17NgIr0+Ggqd9u9Nhftl+99z9PvW0BcXMXrqGsQO77JrJUh4MEzBjyviBDT7MQYEuIqlixWx4+beweTUEsuDE38PxV0Jm9n6fetqCYq7/1xIA5n+xjj/+eFCDncmyJwp0EWnYtq6D2dfA0um+3S0Pxj8CnQ6NyekLisp4aO7nu/3uuYXFzJh4fMoEeRUFuog0TM7Bkukw+2rYvh4ym8FJk2DoxRDIiMklCorK+NkTfmOKSJ1bN43J+RNNgS4iDc/Gb3wxrc9f9e3eJ8IZD8EBvWN6mRcWl9QI86wM46Lh+1a0K9kU6CLScITDsPhpeG0ylG+GJq3hlFv9Rs37uGy/NlVL+ddu3rnb74/ontx65vtLgS4iDUPpl/DS5fD1fN/uPw5Ouxdad43ZJaYtKOa5hcUsX7OJUNiRmREgMwChsB+Zp3KYQ5SBbmZjgAeBDOBJ59wd1T5vA/wdyKk85z3Oub/EuK8iko5CQb846M3bILgDmneAcXfBgLNiOiqPnMmy69KhMOcNyaFr22YpNZulLvUGupllAI8Co4ESYKGZzXTOLY847BJguXPuDDPrCKwws2ecc+Vx6bWIpIdvl8LMibD6Q98+/Fw49XZoEbvl9VWPV15b9m2Nz7IyA5w1uHvKB3mVaEboQ4CVzrlCADN7FhgPRAa6A1qZmQEtgfVAMMZ9FZF0EdwJ8+/1P+EgtO4Gpz8AB58S08tEbuKcUW0/i1MOaxibUsRSNIHeDVgV0S4BhlY75hFgJrAaaAWc65wLVzsGM7sQuBAgJ6fhr7oSkThYtdCPyr//zLfzfg0n3wRNW8f0MgVFZUyasZRQ5Qr+UBiG9GpHk6wMxg7skhIrP/dWNIFe20Os6nujngp8BIwC+gKvm9l859ym3b7k3FRgKkBeXl71c4hIOivfCv+uLKaFgwP6wpkPQ6/j4nK5/MJSQtX2/ezXuRW3NZDdheIhmkAvAXpEtLvjR+KRzgfucM45YKWZfQUcAnwQk16KSGorfAtmXgYbiiqLaV0GI66DrGZxu2RkPRaAzAawiXO8RRPoC4F+ZtYb+AY4D5hQ7Zhi4CRgvpl1BvoDhbHsqIikoO0b4PVJfqNmgM4D/ai82+CYXypym7jcnu3I7dmOf/zXMF5YXIIDzk6jl591qTfQnXNBM5sIzMFPW3zKObfMzC6u/Pxx4BbgaTNbgn9Ec41zbl0c+y0iDd1nr/hiWlu+hYxsGH41HHcFZGTF/FIFRWX8/Em/hL9qm7iqUE/3EI8U1Tx059wsYFa13z0e8efVQGxfT4tIatqy1tdfWfYv3+4+xBfT6tg/5peqGpV/s2E75cEwYQcVldvENaYgr6KVoiISG87BJ/8Hr14D28sgqzmcdCMM+a+YFdOKFDkq9ys+jVDYkZUZaNDbxMWTAl1E9t+GVfDylbDydd/uMwLOeBDa9YrbJfMLS3eNytNtxee+UqCLyL4Lh6HgKXj9Rijf4jdmPvWPcOTPY7psvzZVs1gqguG0W/G5rxToIrJv1q30+3oWv+fbh5zui2m1OjAhl8/t2S4ldxWKJwW6iOydUBDefxjevB1CO6FFJzjtHjhsfFwuV306YqTGNoulPgp0EYnet0tgxiWw5mPfPmICnHobND8gLperazqi1E6BLiL1q9gB8+6Gdx/wxbTa9IAzHoCDTo7rZSNffDbm6YjRUqCLyJ4VL/DFtNZVbqQ85EI4aTI0aRX3S1d/8dlYpyNGS4EuIrXbuQX+fQss+DPgoH0/v2y/5zEJ64JefO4dBbqI1LRyLrx0BWwsBsuA4y6H4ddAVtOEd0UvPqOnQBeRH2wvgzk3wEfP+PaBg2D8o9DliLhcbk8zWGTvKdBFxFs+E2ZdBVu+g4wmMOIaX+Y2DsW0QDNY4kGBLtLYbf7OB/mnM327xzD/rLzjwXG9rGawxJ4CXaSxcg4+/ge8eh3s2ABZLfxWcEdfAIFAfd/eb5rBEnsKdJHGaEOxf+n55Vzf7nuSn1feNnH7bGoGS+wp0EUak3AYFj4Jb9wEFVuhaVsYcwcccV7ci2nVRjNYYkuBLtJYfP+5L6a1Kt+3DxsP4+6Blp2S2y+JGQW6SLoLVcC7D8Lbd0KoHFp29kF+2JnJ7pnEmAJdJJ2t+dgX0/p2iW8f+f/g1FuhmR5zpCMFukg6qtgBb98B7z4ELuRfdp7xIPQdFdPLTFtQzOylaxg7sAsThibuharUToEukm6K3vfFtEpXAgZDL4ZRk6BJy5heZtqCYq7/lx/5z/9iHYBCPcniP9lURBJj52Z45Sr4yxgf5h0Ohv+cA2PvjHmYA8xeumaPbUk8jdBF0sEXb8DLV8DGVRDIhOOvhBN/D5lNYnaJ6nVXxg7ssmtkDjB2YJeYXUv2jQJdJJVtWw9zrvcrPgG6HAnjH/FFtWKotrorVY9X9Ay94VCgi6Qi52D5DF+DZev3kNkURlwHx0yEjNj9a1310rNZVkatdVcmDM1RkDcgCnSRVLP5W3jld/DZy76dc6wvptXhoJhdoqCojMff/pLXl3+363dZGYaFnequNGAKdJFU4Rx8+Hd47QbYsRGyW8LomyH3P2NaTKvq8cqOivBuvz+sS2tOGXCg6q40YAp0kVRQ9jW8dDkUvuXbB42G0++Htj1ifqmqsrbVnXu0Hq80dAp0kYYsHIIPpsLcKVCxDZod4KchDjonZsW0qs9eiSxrawYDurZRmKcIBbpIQ7X2M19Mq+QD3x5wFoy9C1p23O9TV4V4u+bZTHl5WY1dg1TWNjVFFehmNgZ4EMgAnnTO3VHLMSOAB4AsYJ1zbnjMeinSmIQq4J0HYN5dlcW0DoTT74NDTtvvUxcUlfH84hKmF5QQDIUJmBF2rsbsFZW1TU31BrqZZQCPAqOBEmChmc10zi2POKYt8CdgjHOu2MxUj1NkX6z+EGZMhO+W+vbgX8LoW6BZ2/0+ddXLzp0VYVzVL50jEDAMzV5JB9GM0IcAK51zhQBm9iwwHlgeccwE4AXnXDGAc25trDsqktYqtsNbt8N7D4MLQ9uecOZD0GdEzC5R9bKzKswNyM4KMPn0AZRtK9fjlTQQTaB3A1ZFtEuAodWOORjIMrO3gFbAg865v1U/kZldCFwIkJOjFywiAHz9jn9Wvr4QLOAXB428HrJbxPQykS87MwLGOXk9OGtwd4V4Gokm0Gt7le6qtTOBXOAkoBnwvpnlO+c+3+1Lzk0FpgLk5eVVP4dI47JjE7xxIyx6yrc7HgLjH4XueXG5nF52pr9oAr0EiJzs2h1YXcsx65xzW4GtZjYPOAL4HBGp6fPXfDGtTd/4YlonXAUn/DamxbRqo5ed6S2aQF8I9DOz3sA3wHn4Z+aRZgCPmFkmkI1/JHN/LDsqkha2lsKr18KS//Ptrkf5UXnnAcntl6SFegPdORc0s4nAHPy0xaecc8vM7OLKzx93zn1qZq8CnwBh/NTGpfHsuEhKcQ6WvQCzroZt63wxrVF/gKH/vV/FtKovCpLGzZxLzqPsvLw8t2jRoqRcWyShNq32xbRWzPLtXif47eDa992v09ZW0lahnv7MrMA5V+uLFq0UFYkX52DxX+G1SbBzEzRpDaOnwOBfxaSYVtU0xOqLgqTxUqCLxMP6Qph5GXw937cPHgOn3QdtusXsEpHTELUoSECBLhJb4RDkPwb/vhWC26F5e19/ZeDZMSumVUXTEKU6BbpIrHy3HGZOhG8KfHvQOTDmDmjRYa9PFe3LTk1DlEgKdJH9FSyHd+6DefdAuAJadfXFtPqP3afT6WWn7CsFusj+KCnwo/K1laWNcs/3uwg1bRP1KapG45u3V7BszSaa1rF/p0h9FOgi+6J8G7x5G+T/yRfTatfb7+vZ+4S9Ok2tFRCBzICvuaGXnbI3FOgie+ureb6YVtnXvpjWsZfCiOshu/len6p6BcQqA7q20f6dstcU6CLR2rERXp8MBU/7dqcBMP5h6Ja7z6esmnpYfYSuLd9kXyjQRaKxYja8fCVsXgOBLDjx93D8lZCZvV+njZx6WPUMfezALgpz2ScKdJE92boOZl8DS6f7drc8GP8IdDo0qq9HM/1QUw8lVhToIrVxDpZMh9lXw/b1kNUcRk2CoRdBIKPerxcUlfHC4hL+uWgVwbDT9ENJCAW6SHUbS+Dl38IXc3y793BfTOuA3nv8WlWIf795J2+tWEtFyO16Lq7ph5IICnSRKuEwLH4aXpsM5ZuhSRs49VY46hd7XLZfUFTG85Wj8YpQzeqlmn4oiaJAFwEo/dIX0yp6x7f7nwan3Qutu+zxa3XNI4cfgvwnud05W3t3SgIo0KVxCwX94qA3b4PgDmjeAcbdDQN+HFUxrbrmkWdmGD/N66Egl4RSoEvj9e1Sv2x/9Ye+ffi5vphW8wOiPkVkCduMgDGifyc6tGqiIJekUKBL4xPc6QtpvXMfhIPQujucfj8cfEqdX6lr+qFK2EpDokCXxmXVQj8q//4z3z76AjjpRmjaus6v1Ff9UPPIpaFQoEvjUL7VbzqR/xjg4IC+vphWr+NqPTxyRK6t3iRVKNAl/RW+5WewbCgCy6gspnUtZDWr9fDqI/LJpw/QVm+SEhTokr62b4DX/gAf/q9vdx7ki2l1ParGoXsakZdtK9dzckkJCnRJT5++DK/8DrZ8CxnZMPxqOO4KyMiqcWg0I3I9J5dUoECX9LJlLcz6PSx/0be7D/HFtDr2r/MrGpFLulCgS3pwDj55Dl69FraXQVYLOPlGP4ulnmJakXPJNSKXVKZAl9S3YZWvVb7ydd/uM9IX02rXM6qvay65pAsFuqSucBgW/Q+8cROUb/EbM596Oxw5Iapl+5E0Ipd0oECX1LRupd/Xs/g93z7kdF9Mq9WBUW0qIZKOFOiSWkJBeP9hePN2CO2EFp3gtHvgsPFA/as6RdKZAl1Sx5pP/LL9NR/79hET+GjA1bz7TYhhLcrI7dlOqzqlUVOgS8NXsQPm3QXvPAAuBG168MXQW/nLd32Z/rfPCIZ+GI3XNmNFpLGIKtDNbAzwIJABPOmcu6OO444G8oFznXPTY9ZLabyKF/hR+brPAYMhF/LhwZfxs78uZWdFcY0t3i4ZeZBmrEijVW+gm1kG8CgwGigBFprZTOfc8lqOuxOYE4+OSiOzcwvMnQIfTAUctO/ni2n1PIb33ly526YS1bd404wVaayiGaEPAVY65woBzOxZYDywvNpxlwLPA0fHtIfS+KycCy9dARuLfTGt4y6H4ddAVlOg5qYS5+T14CxtKCESVaB3A1ZFtEuAoZEHmFk34MfAKPYQ6GZ2IXAhQE5Ozt72VdLdtvW+mNZHzwDwdVZfPj36dsaefOpuh2khkEjtogn02lZoVN9C8QHgGudcyPawoMM5NxWYCpCXl1dze3RpvJbPgFeugq1rCQWyuWfnWTyxYxzBfwf5Y5tiJgzdfQCgxyoiNUUT6CVAj4h2d2B1tWPygGcrw7wDMM7Mgs65F2PRSUljm7+jbPrltCua7ds5x3Bt+QX88+sfapXPXrqmRqCLSE2BKI5ZCPQzs95mlg2cB8yMPMA519s518s51wuYDvxGYS575Bx8+Aw7H8qjXdFstrimTAmfT8GoZzjqqCG7HTp2YJckdVIktdQ7QnfOBc1sIn72SgbwlHNumZldXPn543Huo6SbsiI2/vMS2qyeTxPg7dDhXF/xa9bQkfZflXHJyIMAPzIfO7CLRuciUTLnkvMoOy8vzy1atCgp15YkCYdh4RNUvHYjWaHtbHAtmFLxC14InwAYmQHjuYuO0bNxkT0wswLnXF5tn2mlqCTE0o8XcsDc39F108dkAa+EhnBjxfmsow0GZASMKeMHKsxF9oMCXeKq4Ku1rJtzNyPXPEW2BVnr2jKp4nzmhP3s1gyD84bkaB65SAwo0CUuCorKeP+duYz6/BZOta/B4LngCG4PTWCLtSJgjoD5UbmekYvEhgJdYm7xl2so+Os1XGwvkWlhVoU7cm3wAt4LD6JJVoAppw+gbFu5FgWJxJgCXWKr6H16T7+IwYEiws54KjiGe4M/pSKjGROGaom+SDwp0CU2dm6GN26GhU/QDljpunFtxX/xifXnHAW5SEIo0GWv1dji7YvXfTGtTSUQyITjf8umXr9mZNEWrtNjFZGEUaDLXonc4q1T5lZeOXg27b98wX/Y5UgY/wgcOIjBwOA+yeypSOOjQJeoVI3KV2/YTnkwxBhbwJTA07T/chNkNoWR18OwSyBD/0iJJIv+7ZM9Kigq4/nFJUwvKCEYCtMlsIE/Z/2F0YGFAGzuPIRW5zwGHQ5Kck9FRIEudap6vLKzIozDcU7G20zK/DutbRvlGS1YM+Q6eo6+BALR1HgTkXhToEud8gtLKQ+G6WZruT3zSU7IWArAxm4jaPPTR+nZpnuSeygikRToAsC0BcU1qhsO69WWX2e9ypX2HM1tJ1sz2rD2uJvpPfI/YA8bmYhIcijQhWkLirn+X0sAmP/FOgAm9N5G7tyJ5FY+K1/f+wwOOPt+erfsmLR+isieKdCF2UvX7PpzFkGy370bXnsWQuXQqgucdh8HHDIuiT0UkWgo0BuZGouC8DsCzf9iHYOskLuypnLopmJ/8OBfwegp0Kxt8josIlFToDcikYuCsjMDPHPBMHJ7tmPC4I4c+dnrHPLVXwkQhna94IyHoM/wZHdZRPaCAr0RqZq1EnZQEQyTX1hKrlsGMy/lsPWFYAEYNtEvEspukezuisheUqCnodoeqwAM69Oe7MwAFcEwbTN38NNv74O3n/EfdjzUL9vvXuvOViKSAhToaWbagmImz1hKKOxokvXDYxWA3J7teOaCYaxZ+CKnFN5J9oo1EMiCE37nfzKzk9x7EdkfCvQ0UlBUxuQZSwmG/cbf5RWVj1WqRulbS8lddC0s/T/f7jrYj8o7D0hSj0UklhToaSS/sJSwc7vagYAxrE97cA6WPg+zr4ZtpZDZDEbdAMN+A4GMJPZYRGJJgZ6iantOXvWMvDwY3rVfZ2677fDsb2DFLP/FXifAGQ9C+75J7L2IxIMCPcVUr34YOf2w6hl5fmEpw3ofQG7pTHh0EuzcBE1a+znlg3+lYloiaUqBnkJ2r37o7Zp+GPHiM7dVGcz8JXw93x908Bg47T5o0y05HReRhFCgp5CqeeRVYW5AVmbAPycHCIcg/zH4960Q3A7N28PYu2Dg2SqmJdIIKNBTSOQ88oyAcU5exObL3y2HmRPhmwJ/8KBzYMyd0KJ9cjstIgmjQG+A6loYtNsz8qrPguXw1h0w7x4IV0CrrnD6/dB/TBLvQESSQYHegOzphWeVqpefAJQU+FH52uWVH54Po2+Gpm2S0HsRSTYFegMRucKzrheeu5Rvgzdvg/w/gQtDu95w5sPQ+4SE91tEGo6o5q+Z2RgzW2FmK83s2lo+/7mZfVL5856ZHRH7rqavyBWedb7wrPLVPHjsGHj/Ed8+9jL47/cU5iJS/wjdzDKAR4HRQAmw0MxmOueWRxz2FTDcOVdmZmOBqcDQeHQ4HeUXlhIK/7DCM8PgvCE5P7zwBNixEV6bBIv/6tudBvhl+90GJ6HHItIQRfPIZQiw0jlXCGBmzwLjgV2B7px7L+L4fEC7B9ehrhWeTbIClFeECQT8Cs+qfT0BWDEbXr4SNlcW0xp+NRx3hYppichuogn0bsCqiHYJex59/xqYXdsHZnYhcCFATk5ObYektbo2mKh19grA1nW+/srS5327W54flXc6NHk3ISINVjSBXtuKFFfL7zCzkfhAP762z51zU/GPY8jLy6v1HOms1g0mIld4VgW5c7Bkug/z7eshqzmMmgRDL1IxLRGpUzSBXgL0iGh3B1ZXP8jMDgeeBMY650pj0730ErkwqNYXngAbS+Dl38IXc3y793BfTOuA3ontrIiknGgCfSHQz8x6A98A5wETIg8wsxzgBeAXzrnPY97LNFHnoxWAcBgK/gKv3wjlm6FJGzj1VjjqF1q2LyJRqTfQnXNBM5sIzAEygKecc8vM7OLKzx8HJgPtgT+ZD5+gc67R7WVW1wrPSLs9WqlS+iXMvAyK3vHt/qfBafdC6y5x7rGIpBNzLjmPsvPy8tyiRYuScu14qOuF5x6FgpD/KLz5RwjugBYdYdzdcNiPNCoXkVqZWUFdA2atFI2RPb3wrNW3S/2y/dUf+vbh58GY26H5AYnpsIikHQX6figoKuOFxSU4YGDXNvW/8AQI7vSFtN65D8JBaN0dzngA+o1OZNdFJA0p0PdBQVEZf377S9749DuqFnhmZxg3nTmQsm3ldT9DX/UBzJgI61b49tEXwEk3QtPWieu8iKQtBfpemragmEmVRbQiVYQcZdvKuWTkQTW/VL4V5t4CCx4HHBzQ1xfT6nVcYjotIo2CAn0vVBXRqh7mAFkZVvtjli/fhJcugw3FYBlw3GUw/BrIapaAHotIY6JAj0LVdMTVG7YTrjYrKGBw8qGduWh4390fs2zfAK/dAB/+3bc7D4LxD0PXoxLXcRFpVBTo9YicjpgZMDIzAgRDYcyMUYd04uLqQQ7w6cvwyu9gy7eQke1H5MddDhlZybkJEWkUFOh1qBqVf7Nh+67piKGw49whPejWtlntLz63rIVZv4flL/p29yG+mFbH/gnvv4g0Pgr0aqpvA5eZESAzYITCjqzMAGdH1iiv4hx88hy8ei1sL4OsFnDyjX4Wi4ppiUiCKNAjFBSV8bMn/OOVKqFQmPOG5NC1rlH5hlXw8hWw8g3f7jPSF9Nq1zNxHRcRQYG+S0FRGVNeWrZbmFdtA3dWbaPycBgW/Q+8cROUb/EbM596Oxw5Qcv2RSQpFOj8sEFzsNp0xMO7t2HyGQNqhvm6L2DmpVD8vm8fegaMuxdadU5Qj0VEamr0gR65QXOk7AyrGeahILz3ELx1B4R2QotOcNo9cNj4BPdaRKSmRh/o+YWlu80tr3WDZoA1n/hiWms+9u0jJsCpt6mYlog0GI0y0CPrllftIlQeDBOwWjZortgB8+6Cdx4AF4I2OXDG/XDQyUnrv4hIbRpdoFc9Lw87t6tueZ27CBXn+2JapV8ABkMugpMmQ5OWSeu/iEhdGk2gT1tQzHMLi1nyzcZdFRLLK+uWXzLyoN2DfOcWmDsFPpgKOGjfzy8QyhmWlL6LiESjUQT6HbM+5fF5hTV+H7BaCmqtnAsvXQEbK4tpHX8FnHg1ZDVNSF9FRPZV2gd6XWGeGfDPy3eNzLeth9f+AB8949sHHg7jH4UuhyewtyIi+y6tA72uMD/lsGrVEZfPgFeugq1rIaMJjLgWjr1UxbREJKWkbaAXFJUxdX7NML/4xD5cO+5Q39j8Hcy6Cj6d6ds5x/iNJzr0S2BPRURiI20DPb+wlGqly38Ic+fgo2kw5zrYsRGyW8LJN0HeryEQSEp/RUT2V9oG+rA+7WmSFWBnRRgzuPCEyjAvK4KXLofCN/2BB50Mp98PbXP2fEIRkQYubQM9t2e73eeX92gDC/4Mb9wMFVuhWTsYcwccfq6KaYlIWkibQI9c/Vn1sjO3Zzv/5+9XwF/OhVUL/MGH/QjG3Q0tOyWvwyIiMZYWgV7b6s/cnu0gVAHvPghv3wmhcmjZGU6711dHFBFJMykf6NWrJVat/szNKvLL9r9b4g886hdwyi3+UYuISBpK+UDPLywlFFH6tplVcPb6J+CJJ3wxrbY5cMZD0HdkEnspIhJ/KR/oVbNZyivCDMlYwdS2f6X1kq8Bg2G/gVF/gOwWye6miEjcpXyg5/Zsxz9+NZDMf9/MoNX/hK1Ah/6+mFaPIcnunohIwqRkoO82o6V8EUe9dAVsKoFAJhz/WzjxKshskuxuiogkVFSBbmZjgAeBDOBJ59wd1T63ys/HAduA/3DOLY5xXwEf5j9/Mp/mwY10y/o7uYH5/oMuR/pR+YGD4nFZEZEGr95AN7MM4FFgNFACLDSzmc655RGHjQX6Vf4MBR6r/N+Yy/9yHSeH3+Om7KfpYJsIBpqQedINMOwSyEjJ/+AQEYmJaBJwCLDSOVcIYGbPAuOByEAfD/zNOeeAfDNra2ZdnHNrYt3hc1ffToes5wFY6A6l2Y/+xMDDB8f6MiIiKSeaSlTdgFUR7ZLK3+3tMZjZhWa2yMwWff/993vbVwA6HHICoayWvNXvOgLnv6IwFxGpFM0IvbZCJ24fjsE5NxWYCpCXl1fj86jk/gcZ/ccyotWB+/R1EZF0Fc0IvQToEdHuDqzeh2NiwwwU5iIiNUQT6AuBfmbW28yygfOAmdWOmQn80rxhwMZ4PD8XEZG61fvIxTkXNLOJwBz8tMWnnHPLzOziys8fB2bhpyyuxE9bPD9+XRYRkdpENc/POTcLH9qRv3s84s8OuCS2XRMRkb2h/dZERNKEAl1EJE0o0EVE0oQCXUQkTZh/n5mEC5t9DxTt49c7AOti2J1UoHtuHHTPjcP+3HNP51zH2j5IWqDvDzNb5JzLS3Y/Ekn33DjonhuHeN2zHrmIiKQJBbqISJpI1UCfmuwOJIHuuXHQPTcOcbnnlHyGLiIiNaXqCF1ERKpRoIuIpIkGHehmNsbMVpjZSjO7tpbPzcweqvz8EzNL+e2Lorjnn1fe6ydm9p6ZHZGMfsZSffcccdzRZhYys58ksn/xEM09m9kIM/vIzJaZ2duJ7mOsRfHPdhsze8nMPq6855Su2mpmT5nZWjNbWsfnsc8v51yD/MGX6v0S6ANkAx8Dh1U7ZhwwG79j0jBgQbL7nYB7PhZoV/nnsY3hniOO+ze+6udPkt3vBPw9t8Xv25tT2e6U7H4n4J6vB+6s/HNHYD2Qney+78c9nwgMBpbW8XnM86shj9B3bU7tnCsHqjanjrRrc2rnXD7Q1sy6JLqjMVTvPTvn3nPOlVU28/G7Q6WyaP6eAS4FngfWJrJzcRLNPU8AXnDOFQM451L9vqO5Zwe0MjMDWuIDPZjYbsaOc24e/h7qEvP8asiBHrPNqVPI3t7Pr/H/D5/K6r1nM+sG/Bh4nPQQzd/zwUA7M3vLzArM7JcJ6118RHPPjwCH4revXAJc7pwLJ6Z7SRHz/Ipqg4skidnm1Ckk6vsxs5H4QD8+rj2Kv2ju+QHgGudcyA/eUl4095wJ5AInAc2A980s3zn3ebw7FyfR3POpwEfAKKAv8LqZzXfObYpz35Il5vnVkAO9YW1OnRhR3Y+ZHQ48CYx1zpUmqG/xEs095wHPVoZ5B2CcmQWdcy8mpIexF+0/2+ucc1uBrWY2DzgCSNVAj+aezwfucP4B80oz+wo4BPggMV1MuJjnV0N+5NIYN6eu957NLAd4AfhFCo/WItV7z8653s65Xs65XsB04DcpHOYQ3T/bM4ATzCzTzJoDQ4FPE9zPWIrmnovx/0WCmXUG+gOFCe1lYsU8vxrsCN01ws2po7znyUB74E+VI9agS+FKdVHec1qJ5p6dc5+a2avAJ0AYeNI5V+v0t1QQ5d/zLcDTZrYE/zjiGudcypbVNbN/ACOADmZWAtwIZEH88ktL/0VE0kRDfuQiIiJ7QYEuIpImFOgiImlCgS4ikiYU6CIiaUKBLiKSJhToIiJp4v8D8GKQzZeBAF8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytest = model(xtraining)\n",
    "ytest = ytest.detach().numpy().reshape(-1)\n",
    "plt.plot(yhat, ytest,  \".\")\n",
    "plt.plot([0, 1], [0, 1], linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We're now visualizing how well our logistic regression model fits the data. yhat contains the fitted values from the logistic regression model fitted using statsmodels.\n",
    "ytest contains the predictions made by our PyTorch logistic regression model after training.\n",
    "Each point on the scatter plot represents a comparison between the actual value and the predicted value for each observation.\n",
    "The diagonal line represents the ideal scenario where predicted values perfectly match the actual values.\n",
    "Deviations from this line indicate the model's ability to predict accurately: points above the line indicate overestimation, while points below indicate underestimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "hZpPdBPYy53z",
    "outputId": "8ee26a76-37fd-4dc4-ea84-9a7f17cd5c3a",
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6660]])\n",
      "tensor([-0.1225])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():  \n",
    "  print(param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "let's examine the parameters of our trained logistic regression model in PyTorch to understand the learned weights and biases. We loop through the parameters of the model.\n",
    "For each parameter, we print its data.\n",
    "This will display the weights and biases that the model has learned during training. By inspecting these values, we can see how the model has adjusted the parameters to fit the data. This step is crucial for understanding the internal workings of the model and verifying that the training process has updated the parameters as expected."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "logisticRegression in pytorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ds4bio]",
   "language": "python",
   "name": "conda-env-.conda-ds4bio-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
